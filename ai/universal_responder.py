#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
Module d'am√©lioration de la r√©ponse pour permettre une interaction plus naturelle
avec l'utilisateur dans tous les contextes.
"""

import logging
import re
import os
import traceback
from typing import Dict, List, Any, Tuple, Optional

logger = logging.getLogger("VynalDocsAutomator.UniversalResponder")

class UniversalResponder:
    """
    Classe qui augmente les capacit√©s de r√©ponse de l'IA en d√©tectant
    et r√©pondant aux entr√©es utilisateur de mani√®re plus naturelle.
    """
    
    def __init__(self):
        """Initialise le r√©pondeur universel"""
        # Patterns pour diff√©rents types d'entr√©es utilisateur
        self.patterns = {
            "greeting": [
                r'\bbonjour\b', r'\bsalut\b', r'\bhello\b', r'\bhey\b', r'\bhi\b',
                r'\bcava\b', r'\b√ßa va\b', r'\bcomment vas[ -]tu\b', r'\bcomment allez[ -]vous\b',
                r'\bcomment √ßa va\b', r'\bcomment cv\b', r'\bcv\b', r'^cv$'
            ],
            "thanks": [
                r'\bmerci\b', r'\bthanks\b', r'\bthank\b', r'\bthx\b', r'\bty\b',
                r'\bje te remercie\b', r'\bje vous remercie\b'
            ],
            "goodbye": [
                r'\bau revoir\b', r'\badieu\b', r'\bciao\b', r'\bbye\b', r'\bgoodbye\b',
                r'\b√† bient√¥t\b', r'\b√† plus\b', r'\b√† \+\b'
            ],
            "help": [
                r'\baide[-\s]moi\b', r'\baide\b', r'\bhelp\b', r'\bbesoin d\'aide\b',
                r'\bcomment [√ßc]a marche\b', r'\bcomment faire\b', r'\bque peux[-\s]tu faire\b'
            ],
            "affirmation": [
                r'\boui\b', r'\bouais\b', r'\byes\b', r'\byep\b', r'\bd\'accord\b',
                r'\bok\b', r'\bbien s√ªr\b', r'\bs√ªr\b', r'\bj\'accepte\b', r'\bvolontiers\b'
            ],
            "negation": [
                r'\bnon\b', r'\bnope\b', r'\bno\b', r'\bpas\b', r'\bpas d\'accord\b',
                r'\bje refuse\b', r'\bje ne veux pas\b', r'\bpassons\b'
            ],
            "confusion": [
                r'\bje ne comprends pas\b', r'\bc\'est confus\b', r'\bc\'est flou\b',
                r'\bje suis perdu\b', r'\bc\'est compliqu√©\b', r'\bqu\'est-ce que [√ßc]a veut dire\b'
            ],
            # Nouvelles intentions
            "question_about_you": [
                r'\bqui es[-\s]tu\b', r'\bc\'est quoi ton nom\b', r'\bcomment t\'appelles[-\s]tu\b',
                r'\btu es qui\b', r'\btu fais quoi\b', r'\btu sers √† quoi\b', r'\bque fais[-\s]tu\b',
                r'\bc\'est quoi ton but\b', r'\bquel est ton r√¥le\b'
            ],
            "small_talk": [
                r'\btu aimes\b', r'\btu pr√©f√®res\b', r'\btu peux\b', r'\btu sais\b',
                r'\bc\'est cool\b', r'\bc\'est g√©nial\b', r'\bc\'est super\b', r'\bc\'est bien\b',
                r'\bje suis content\b', r'\bje suis heureux\b', r'\bje suis satisfait\b',
                r'\btu connais\b', r'\bquelle heure\b', r'\bquel jour\b', r'\bquel temps\b'
            ],
            "compliment": [
                r'\btu es g√©nial\b', r'\btu es super\b', r'\btu es intelligent\b', r'\btu es efficace\b',
                r'\bmerci pour ton aide\b', r'\btu m\'aides beaucoup\b', r'\btu es utile\b',
                r'\bc\'est pratique\b', r'\bc\'est rapide\b', r'\bc\'est parfait\b'
            ],
            "frustration": [
                r'\bc\'est long\b', r'\bc\'est lent\b', r'\bc\'est compliqu√©\b', r'\bc\'est difficile\b',
                r'\bje n\'arrive pas\b', r'\bc\'est p√©nible\b', r'\bc\'est ennuyeux\b',
                r'\b√ßa ne marche pas\b', r'\b√ßa fonctionne pas\b', r'\bc\'est impossible\b',
                r'\bpfffff\b', r'\bpfff\b', r'\bpff\b', r'\bargh\b', r'\braaah\b'
            ],
            "question_g√©n√©rale": [
                r'\bpourquoi\b', r'\bcomment\b', r'\bquand\b', r'\bo√π\b', r'\bqui\b', r'\bquoi\b',
                r'\bquel\b', r'\bquelle\b', r'\bcombien\b', r'\b√† quoi\b', r'\best-ce que\b',
                r'\bqu\'est-ce\b', r'\btu penses\b', r'\btu crois\b', r'\bton avis\b',
                r'\bpenses-tu\b', r'\bcrois-tu\b'
            ],
            "demande_avis": [
                r'\bque penses[-\s]tu\b', r'\bquel est ton avis\b', r'\bqu\'en penses[-\s]tu\b',
                r'\bcomment trouves[-\s]tu\b', r'\best-ce bien\b', r'\best-ce bon\b',
                r'\best-ce correct\b', r'\bton opinion\b', r'\bton conseil\b'
            ]
        }
    
    def detect_intent(self, message: str) -> Tuple[str, float]:
        """
        D√©tecte l'intention de l'utilisateur dans le message.
        
        Args:
            message (str): Le message de l'utilisateur
            
        Returns:
            Tuple[str, float]: L'intention d√©tect√©e et sa probabilit√©
        """
        # Normaliser le message
        message = message.lower().strip()
        
        # D√©tecter les intentions
        for intent, patterns in self.patterns.items():
            for pattern in patterns:
                if re.search(pattern, message):
                    return intent, 0.9  # Haute probabilit√© si match direct
        
        return "unknown", 0.0
    
    def should_intercept(self, message: str, context: Dict[str, Any]) -> bool:
        """
        D√©termine si le message devrait √™tre intercept√© et trait√© diff√©remment.
        
        Args:
            message (str): Le message de l'utilisateur
            context (Dict[str, Any]): Le contexte actuel de la conversation
            
        Returns:
            bool: True si le message devrait √™tre intercept√©
        """
        intent, confidence = self.detect_intent(message)
        
        # V√©rifier d'abord les intentions li√©es √† une demande d'avis ou question g√©n√©rale
        if intent in ["demande_avis", "question_g√©n√©rale", "frustration"]:
            current_state = context.get("state", "initial")
            if current_state not in ["initial", "greeting"]:
                return True
        
        # Intentions √† toujours intercepter, quelle que soit l'√©tape du processus
        always_intercept = ["thanks", "goodbye", "help", "confusion", 
                           "question_about_you", "compliment"]
        if intent in always_intercept and confidence > 0.7:
            return True
            
        # Intentions √† intercepter uniquement si on est dans un processus de document
        current_state = context.get("state", "initial")
        if current_state not in ["initial", "greeting"]:
            # En plein processus, intercepter les digressions
            process_intercept = ["greeting", "small_talk"]
            if intent in process_intercept and confidence > 0.7:
                return True
        
        # Cas sp√©cial: question courte non li√©e au processus
        if len(message.split()) <= 3 and intent == "random_question":
            return True
            
        return False
    
    def _ensure_response_consistency(self, response: str, context: Dict[str, Any]) -> str:
        """
        Assure la coh√©rence des r√©ponses en fonction du contexte.
        
        Args:
            response (str): La r√©ponse g√©n√©r√©e
            context (Dict[str, Any]): Le contexte actuel
            
        Returns:
            str: La r√©ponse corrig√©e si n√©cessaire
        """
        current_state = context.get("state", "initial")
        
        # Si on est dans un √©tat sp√©cifique, s'assurer que la r√©ponse est coh√©rente
        if current_state == "document_creation":
            if not any(doc_type in response.lower() for doc_type in self.patterns.keys()):
                response = self._handle_document_creation()
        elif current_state == "template_selection":
            if not any(word in response.lower() for word in ["mod√®le", "template", "exemple"]):
                response = self._handle_template_selection()
                
        # Ajouter un rappel si n√©cessaire
        if current_state not in ["initial", "greeting"]:
            reminder = self._get_contextual_reminder(current_state)
            if reminder and reminder not in response:
                response = f"{response}\n\n{reminder}"
                
        return response

    def _handle_document_creation(self) -> str:
        """G√®re la cr√©ation d'un nouveau document"""
        return ("Tr√®s bien ! Quel type de document souhaitez-vous cr√©er ?\n\n"
                "üìù Contrat\n"
                "üí∞ Facture\n"
                "üìä Proposition\n"
                "üìà Rapport\n"
                "‚úâÔ∏è Lettre\n"
                "üîñ Attestation\n"
                "üìÑ Autre")
                
    def _handle_template_selection(self) -> str:
        """G√®re la s√©lection d'un mod√®le"""
        return ("Voici les mod√®les disponibles :\n\n"
                "üìù Mod√®les de contrats\n"
                "üí∞ Mod√®les de factures\n"
                "üìä Mod√®les de propositions\n"
                "üìà Mod√®les de rapports\n"
                "‚úâÔ∏è Mod√®les de lettres\n"
                "üîñ Mod√®les d'attestations\n\n"
                "Quel type de mod√®le vous int√©resse ?")

    def get_response(self, message: str, context: Dict[str, Any]) -> Optional[Tuple[str, Dict[str, Any]]]:
        """
        G√©n√®re une r√©ponse appropri√©e au message si n√©cessaire.
        
        Args:
            message (str): Le message de l'utilisateur
            context (Dict[str, Any]): Le contexte actuel de la conversation
            
        Returns:
            Optional[Tuple[str, Dict[str, Any]]]: La r√©ponse et le contexte mis √† jour, ou None
        """
        try:
            intent, confidence = self.detect_intent(message)
            current_state = context.get("state", "initial")
            
            # V√©rifier si le message devrait √™tre intercept√©
            if self.should_intercept(message, context):
                # Obtenir la r√©ponse de base
                response, new_context = self._get_base_response(message, intent, context)
                
                # Assurer la coh√©rence de la r√©ponse
                if response:
                    response = self._ensure_response_consistency(response, new_context)
                
                return response, new_context
            
            # Si le message ne doit pas √™tre intercept√©, retourner None
            return None, context
            
        except Exception as e:
            logger.error(f"Erreur lors de la g√©n√©ration de la r√©ponse: {e}")
            return self.get_error_message(), context

    def _get_base_response(self, message: str, intent: str, context: Dict[str, Any]) -> Tuple[Optional[str], Dict[str, Any]]:
        """
        Obtient la r√©ponse de base en fonction de l'intention.
        
        Args:
            message (str): Le message de l'utilisateur
            intent (str): L'intention d√©tect√©e
            context (Dict[str, Any]): Le contexte actuel
            
        Returns:
            Tuple[Optional[str], Dict[str, Any]]: La r√©ponse et le contexte mis √† jour
        """
        current_state = context.get("state", "initial")
        
        # Copier le contexte pour ne pas le modifier directement
        new_context = context.copy()
        
        # Traiter les intentions sp√©ciales
        if intent in ["greeting", "thanks", "goodbye", "help", "confusion"]:
            return self._handle_special_intent(intent, new_context)
            
        # Traiter les questions pendant le processus
        if intent in ["question_g√©n√©rale", "demande_avis"] and current_state not in ["initial", "greeting"]:
            return self._handle_question(message, intent, new_context)
            
        # Traiter les demandes de document
        if any(word in message.lower() for word in ["document", "contrat", "mod√®le"]):
            return self._handle_document_request(message, new_context)
            
        # Par d√©faut, laisser le mod√®le principal g√©rer la r√©ponse
        return None, new_context

    def _handle_special_intent(self, intent: str, context: Dict[str, Any]) -> Tuple[str, Dict[str, Any]]:
        """
        G√®re les intentions sp√©ciales comme les salutations et les remerciements.
        
        Args:
            intent (str): L'intention d√©tect√©e
            context (Dict[str, Any]): Le contexte actuel
            
        Returns:
            Tuple[str, Dict[str, Any]]: La r√©ponse et le contexte mis √† jour
        """
        # D√©finir des r√©ponses pour les intentions sp√©ciales
        responses = {
            "greeting": [
                "Bonjour ! Je suis l√† pour vous aider avec vos documents. Que puis-je faire pour vous ?",
                "Bonjour ! Comment puis-je vous aider aujourd'hui ?",
                "Bonjour ! Je suis votre assistant de documents. Que souhaitez-vous faire ?"
            ],
            "thanks": [
                "Je vous en prie !",
                "C'est avec plaisir !",
                "Pas de probl√®me, je suis l√† pour vous aider."
            ],
            "goodbye": [
                "Au revoir ! N'h√©sitez pas √† revenir si vous avez besoin d'aide.",
                "√Ä bient√¥t ! Je reste disponible pour vos futures demandes.",
                "Au revoir et bonne journ√©e !"
            ],
            "help": [
                "Je peux vous aider √† cr√©er diff√©rents types de documents. Voici ce que je peux faire :\n\n"
                "üìÑ Cr√©er un nouveau document\n"
                "- Utiliser un mod√®le existant\n"
                "- Remplir des mod√®les avec vos informations\n\n"
                "Pour commencer, dites-moi simplement ce que vous souhaitez.",
                "Besoin d'aide ? Je peux vous accompagner pour :\n\n"
                "- Cr√©er un nouveau document\n"
                "- Utiliser un mod√®le existant\n"
                "- Remplir des mod√®les avec vos informations\n\n"
                "Dites-moi simplement ce que vous voulez faire."
            ],
            "confusion": [
                "Pas de probl√®me, je vais essayer d'√™tre plus clair. Que souhaitez-vous faire ?\n\n"
                "1. Cr√©er un document\n"
                "2. Utiliser un mod√®le\n"
                "3. Autre chose",
                "Je comprends votre confusion. Pour simplifier, dites-moi si vous voulez :\n\n"
                "1. Cr√©er un document\n"
                "2. Utiliser un mod√®le existant\n"
                "3. Autre chose"
            ]
        }
        
        # Mettre √† jour le contexte
        # Pour les salutations, passer √† l'√©tat "greeting"
        if intent == "greeting":
            context["state"] = "greeting" if context["state"] == "initial" else context["state"]
            context["last_action"] = "greeting"
        
        # Pour les autres intentions, ne pas modifier l'√©tat
        # mais mettre √† jour la derni√®re action
        else:
            context["last_action"] = intent
        
        # S√©lectionner une r√©ponse al√©atoire pour l'intention
        import random
        response = random.choice(responses.get(intent, ["Je suis d√©sol√©, je ne comprends pas."]))
        
        return response, context

    def get_error_message(self) -> str:
        """Retourne un message d'erreur standard"""
        return """Je suis d√©sol√©, mais j'ai rencontr√© un probl√®me. Essayons de nouveau.

Vous pouvez dire "Je veux un document" pour commencer ou me poser une question."""
    
    def _get_contextual_reminder(self, current_state):
        """
        G√©n√®re un rappel contextuel bas√© sur l'√©tat actuel.
        
        Args:
            current_state (str): L'√©tat actuel de la conversation
            
        Returns:
            str: Le rappel contextuel
        """
        if current_state == "choosing_category":
            return "Pour continuer, veuillez choisir une cat√©gorie de document parmi celles propos√©es."
        elif current_state == "choosing_model":
            return "Pour continuer, veuillez s√©lectionner un mod√®le de document parmi ceux propos√©s."
        elif current_state == "model_selected":
            return "Pour continuer, veuillez choisir une action √† effectuer sur le document s√©lectionn√©."
        else:
            return "Maintenant, revenons √† votre document."
            
    def _verify_llama_availability(self):
        """
        V√©rifie si Llama est disponible et fonctionnel.
        """
        try:
            import requests
            url = "http://localhost:11434/api/version"
            response = requests.get(url, timeout=2)
            if response.status_code == 200:
                return True
            return False
        except Exception as e:
            logger.error(f"Erreur lors de la v√©rification de Llama: {e}")
            return False

    def _get_llama_response(self, message: str) -> str:
        """
        Obtient une r√©ponse de Llama pour les questions g√©n√©rales et complexes.
        """
        # V√©rifier d'abord si Llama est disponible
        if not self._verify_llama_availability():
            logger.warning("Llama n'est pas disponible, utilisation du comportement standard")
            return None
            
        try:
            import requests
            import json
            
            # Configuration de la requ√™te Llama
            url = "http://localhost:11434/api/generate"
            
            # Construire le prompt avec le contexte appropri√©
            prompt = f"""Tu es un assistant professionnel et amical. 
            R√©ponds √† cette demande de mani√®re claire et d√©taill√©e : {message}
            
            Important:
            - Reste professionnel et courtois
            - Donne des explications claires et concises
            - Si tu n'es pas s√ªr, dis-le honn√™tement
            - N'invente pas d'informations
            """
            
            # Param√®tres de la requ√™te
            data = {
                "model": "llama2",
                "prompt": prompt,
                "stream": False,
                "temperature": 0.7,
                "max_tokens": 500
            }
            
            # Envoyer la requ√™te avec timeout
            response = requests.post(url, json=data, timeout=10)
            
            if response.status_code == 200:
                # Traiter la r√©ponse
                response_data = response.json()
                if "response" in response_data:
                    return response_data["response"].strip()
            
            raise Exception(f"Erreur de r√©ponse Llama: {response.status_code}")
            
        except Exception as e:
            logger.error(f"Erreur lors de l'appel √† Llama: {e}")
            return None

    def apply_to_ai_model(self, AIModel):
        """
        Applique le r√©pondeur universel au mod√®le d'IA.
        
        Args:
            AIModel (class): La classe du mod√®le d'IA
            
        Returns:
            class: La classe modifi√©e
        """
        # Sauvegarde des m√©thodes originales
        original_generate_response = AIModel.generate_response
        responder = self
        
        def enhanced_generate_response(self, message, stream=False):
            """
            Version am√©lior√©e de generate_response qui utilise le r√©pondeur universel
            et fait appel √† Llama pour les questions g√©n√©rales.
            """
            try:
                # Si le message est vide
                if not message or len(message.strip()) == 0:
                    return "Je ne peux pas traiter un message vide. Veuillez me dire ce que vous souhaitez faire."
                
                # Normalisation du message
                normalized_message = message.lower().strip()
                print(f"DEBUG - Message re√ßu: '{message}'")
                print(f"DEBUG - √âtat actuel: '{self.current_context.get('state', 'initial')}'")
                
                # Obtenir l'√©tat actuel
                current_state = self.current_context.get("state", "initial")
                
                # Si nous sommes dans un √©tat de traitement de document, utiliser la logique standard
                document_states = ["asking_document_type", "choosing_category", "choosing_model", 
                                 "model_selected", "filling_document"]
                if current_state in document_states:
                    return original_generate_response(self, message, stream)
                
                # Patterns pour d√©tecter les demandes li√©es aux documents
                document_patterns = [
                    r'(?:je\s+(?:veux|voudrais|souhaite|aimerais)\s+)?(?:un\s+)?document',
                    r'cr√©er\s+(?:un\s+)?document',
                    r'nouveau\s+document',
                    r'mod√®le\s+de\s+document',
                    r'template',
                    r'formulaire',
                    r'contrat',
                    r'facture'
                ]
                
                # Si le message correspond √† une demande de document
                if any(re.search(pattern, normalized_message) for pattern in document_patterns):
                    return self._handle_document_request(message)
                
                # Pour les autres cas, v√©rifier si c'est une demande complexe ou g√©n√©rale
                complex_patterns = [
                    r'pourquoi',
                    r'comment',
                    r'explique',
                    r'analyse',
                    r'compare',
                    r'diff√©rence',
                    r'meilleur',
                    r'conseil',
                    r'avis',
                    r'pense[sz]',
                    r'suggestion'
                ]
                
                # Si c'est une demande complexe ou g√©n√©rale, utiliser Llama
                if any(re.search(pattern, normalized_message) for pattern in complex_patterns):
                    print("DEBUG - Utilisation de Llama pour une demande complexe/g√©n√©rale")
                    llama_response = self._get_llama_response(message)
                    if llama_response:
                        return llama_response
                    else:
                        print("DEBUG - Llama non disponible, utilisation du comportement standard")
                
                # Pour tout autre cas, utiliser la r√©ponse standard
                return original_generate_response(self, message, stream)
                
            except Exception as e:
                logger.error(f"Erreur dans enhanced_generate_response: {e}")
                print(f"DEBUG - Exception dans enhanced_generate_response: {e}")
                return original_generate_response(self, message, stream)

        def _similarity_score(self, str1, str2):
            """
            Calcule un score de similarit√© entre deux cha√Ænes.
            """
            # Normaliser les cha√Ænes
            str1 = str1.lower().strip()
            str2 = str2.lower().strip()
            
            # Si une cha√Æne est vide, retourner 0
            if not str1 or not str2:
                return 0
            
            # Si les cha√Ænes sont identiques, retourner 1
            if str1 == str2:
                return 1
            
            # Si une cha√Æne est contenue dans l'autre
            if str1 in str2:
                return len(str1) / len(str2)
            if str2 in str1:
                return len(str2) / len(str1)
            
            # Calculer la distance de Levenshtein
            try:
                import Levenshtein
                distance = Levenshtein.distance(str1, str2)
                max_len = max(len(str1), len(str2))
                return 1 - (distance / max_len)
            except ImportError:
                # Fallback si Levenshtein n'est pas disponible
                # Compter les caract√®res communs
                common = sum(1 for c in str1 if c in str2)
                return common / max(len(str1), len(str2))

        # Remplacer la m√©thode originale
        AIModel.generate_response = enhanced_generate_response
        
        return AIModel

    def _transfer_to_main_model(self, context: Dict[str, Any], message: str) -> Tuple[None, Dict[str, Any]]:
        """
        Transf√®re le contr√¥le au mod√®le principal en mettant √† jour le contexte appropri√©.
        
        Args:
            context (Dict[str, Any]): Le contexte actuel
            message (str): Le message de l'utilisateur
            
        Returns:
            Tuple[None, Dict[str, Any]]: None et le contexte mis √† jour
        """
        # Pr√©parer le nouveau contexte
        new_context = context.copy()
        
        # Sauvegarder l'√©tat de UniversalResponder pour le mod√®le principal
        new_context["universal_responder_state"] = {
            "state": context.get("state"),
            "document_type": context.get("document_type"),
            "category": context.get("category"),
            "model": context.get("model"),
            "details": context.get("details", {})
        }
        
        # Transf√©rer l'√©tat au mod√®le principal
        current_state = context.get("state")
        
        # Pour un document s√©lectionn√© √† partir d'un mod√®le
        if current_state == "model_ready":
            new_context["state"] = "model_selected"
            new_context["last_action"] = "model_selection"
            new_context["category"] = context.get("category")
            # Ne pas d√©finir model_ready ici pour √©viter la confusion avec l'√©tat du mod√®le principal
        
        # Pour un nouveau document cr√©√©
        elif current_state == "document_ready":
            new_context["state"] = "document_creation"
            new_context["last_action"] = "document_creation"
            new_context["document_type"] = context.get("document_type")
            # Conserver les d√©tails pour le mod√®le principal
            if "details" in context and isinstance(context["details"], dict):
                for key, value in context["details"].items():
                    new_context[key] = value
        
        # Logger le transfert
        logger.info(f"Transfert au mod√®le principal: {current_state} -> {new_context['state']}")
        
        return None, new_context 

    def _handle_document_request(self, message: str, context: Dict[str, Any]) -> Tuple[str, Dict[str, Any]]:
        """
        G√®re une demande de document de mani√®re intelligente.
        
        Args:
            message (str): Le message de l'utilisateur
            context (Dict[str, Any]): Le contexte actuel
            
        Returns:
            Tuple[str, Dict[str, Any]]: La r√©ponse et le contexte mis √† jour
        """
        # Normaliser le message
        normalized_message = message.lower().strip()
        
        # Mettre √† jour le contexte
        new_context = context.copy()
        new_context["state"] = "asking_document_type"
        new_context["last_action"] = "demande_document"
        
        # D√©tecter si l'utilisateur a d√©j√† exprim√© une pr√©f√©rence dans sa demande
        create_patterns = [
            r'(?:je\s+(?:veux|voudrais|souhaite|aimerais)\s+)?cr√©er\s+(?:un\s+)?(?:nouveau\s+)?document',
            r'nouveau\s+document',
            r'faire\s+un\s+(?:nouveau\s+)?document',
            r'r√©diger\s+(?:un\s+)?document',
            r'√©crire\s+(?:un\s+)?document'
        ]
        
        use_patterns = [
            r'utiliser\s+(?:un\s+)?(?:mod√®le|template|exemple)',
            r'mod√®le\s+existant',
            r'template\s+existant',
            r'voir\s+les\s+mod√®les',
            r'choisir\s+(?:un\s+)?mod√®le'
        ]
        
        # Si l'utilisateur veut cr√©er un nouveau document
        if any(re.search(pattern, normalized_message) for pattern in create_patterns):
            new_context["state"] = "creating_new"
            new_context["last_action"] = "creer_nouveau_document"
            return """Pour cr√©er un nouveau document, j'ai besoin de quelques informations :

1. Quel type de document souhaitez-vous cr√©er ?
2. Quel est son objectif ?
3. Quelles informations doit-il contenir ?

Vous pouvez me donner ces informations comme vous le souhaitez.""", new_context
            
        # Si l'utilisateur veut utiliser un mod√®le existant
        elif any(re.search(pattern, normalized_message) for pattern in use_patterns):
            new_context["state"] = "choosing_category"
            new_context["last_action"] = "choisir_modele_existant"
            return self._show_available_categories()
            
        # Si l'intention n'est pas claire, demander plus de pr√©cisions
        return """Je peux vous aider de deux fa√ßons :

üìù Utiliser un mod√®le existant : Je vous montrerai les mod√®les disponibles par cat√©gorie
‚ú® Cr√©er un nouveau document : Je vous guiderai dans la cr√©ation d'un document personnalis√©

Que pr√©f√©rez-vous ?""", new_context 

    def _show_available_categories(self):
        """
        Affiche les cat√©gories de documents disponibles de mani√®re intelligente.
        """
        try:
            # V√©rifier si le chemin des mod√®les est d√©fini
            if not hasattr(self, 'models_path'):
                self.models_path = os.path.join(os.path.dirname(os.path.dirname(__file__)), 'data', 'templates')
            
            # V√©rifier que le dossier existe
            if not os.path.exists(self.models_path):
                logger.error(f"Le dossier des mod√®les n'existe pas: {self.models_path}")
                return """‚ùå Je suis d√©sol√©, je ne trouve pas le dossier des mod√®les.
                
Veuillez contacter l'administrateur syst√®me."""
            
            # Lister les cat√©gories (dossiers)
            categories = []
            category_info = {}
            
            for item in os.listdir(self.models_path):
                item_path = os.path.join(self.models_path, item)
                if os.path.isdir(item_path) and not item.startswith('.'):
                    # Compter les mod√®les dans la cat√©gorie
                    model_count = len([f for f in os.listdir(item_path) 
                                     if os.path.isfile(os.path.join(item_path, f)) 
                                     and not f.startswith('.')])
                    
                    # Normaliser le nom de la cat√©gorie
                    normalized_name = item.lower().strip()
                    if normalized_name not in category_info:
                        category_info[normalized_name] = {
                            'display_name': item,
                            'count': model_count,
                            'path': item_path
                        }
                    else:
                        # Fusionner les cat√©gories similaires
                        category_info[normalized_name]['count'] += model_count
                    
                    categories.append(normalized_name)
            
            # Si aucune cat√©gorie n'est trouv√©e
            if not categories:
                logger.warning("Aucune cat√©gorie trouv√©e")
                return """‚ùå Je ne trouve aucune cat√©gorie de document.
                
Veuillez contacter l'administrateur syst√®me pour ajouter des mod√®les."""
            
            # Regrouper les cat√©gories similaires
            merged_categories = {}
            for cat in categories:
                base_name = re.sub(r's$', '', cat)  # Enlever le 's' final si pr√©sent
                if base_name not in merged_categories:
                    merged_categories[base_name] = category_info[cat]
                else:
                    merged_categories[base_name]['count'] += category_info[cat]['count']
            
            # Trier les cat√©gories par nombre de mod√®les
            sorted_categories = sorted(merged_categories.items(), 
                                    key=lambda x: (-x[1]['count'], x[0]))
            
            # Construire le message de r√©ponse
            response = """üìÇ Voici les cat√©gories de documents disponibles :

"""
            for i, (cat_name, info) in enumerate(sorted_categories, 1):
                model_count = info['count']
                display_name = info['display_name'].capitalize()
                emoji = self._get_category_emoji(cat_name)
                response += f"{emoji} {display_name} ({model_count} mod√®le{'s' if model_count > 1 else ''})\n"
            
            response += """
Vous pouvez me dire quelle cat√©gorie vous int√©resse en utilisant son nom.
Par exemple : "Je voudrais voir les contrats" ou "Montre-moi les factures"."""
            
            # Mettre √† jour le contexte avec les cat√©gories normalis√©es
            self.current_context = {
                "state": "choosing_category",
                "last_action": "afficher_categories",
                "available_categories": list(merged_categories.keys()),
                "category_info": merged_categories
            }
            
            return response
            
        except Exception as e:
            logger.error(f"Erreur lors de l'affichage des cat√©gories: {e}")
            logger.error(traceback.format_exc())
            return """‚ùå Une erreur s'est produite lors de la r√©cup√©ration des cat√©gories.
            
Veuillez r√©essayer ou contacter l'administrateur syst√®me."""

    def _get_category_emoji(self, category_name):
        """
        Retourne un emoji appropri√© pour une cat√©gorie donn√©e.
        """
        emoji_map = {
            'contrat': 'üìÑ',
            'facture': 'üí∞',
            'juridique': '‚öñÔ∏è',
            'commercial': 'ü§ù',
            'bancaire': 'üè¶',
            'administratif': 'üìã',
            'import': 'üö¢',
            'proposition': 'üìä',
            'autre': 'üìé',
            'document': 'üìë'
        }
        return emoji_map.get(category_name.lower(), 'üìÅ')

    def _show_available_models(self, category):
        """
        Affiche les mod√®les disponibles dans une cat√©gorie de mani√®re intelligente.
        """
        try:
            # V√©rifier si le chemin des mod√®les est d√©fini
            if not hasattr(self, 'models_path'):
                self.models_path = os.path.join(os.path.dirname(os.path.dirname(__file__)), 'data', 'templates')
            
            # Obtenir les informations de la cat√©gorie depuis le contexte
            category_info = self.current_context.get("category_info", {})
            if category.lower() in category_info:
                category_path = category_info[category.lower()]['path']
                display_name = category_info[category.lower()]['display_name']
            else:
                # Fallback sur le chemin direct
                category_path = os.path.join(self.models_path, category)
                display_name = category
            
            # V√©rifier que le dossier existe
            if not os.path.exists(category_path):
                logger.error(f"La cat√©gorie n'existe pas: {category_path}")
                return f"""‚ùå Je suis d√©sol√©, je ne trouve pas la cat√©gorie "{category}".
                
Veuillez choisir une autre cat√©gorie."""
            
            # Lister les mod√®les (fichiers)
            models = []
            for item in os.listdir(category_path):
                item_path = os.path.join(category_path, item)
                if os.path.isfile(item_path) and not item.startswith('.'):
                    # Obtenir les m√©tadonn√©es du fichier
                    size = os.path.getsize(item_path)
                    mtime = os.path.getmtime(item_path)
                    
                    # Nettoyer le nom du fichier
                    clean_name = self._clean_model_name(item)
                    
                    models.append({
                        'filename': item,
                        'clean_name': clean_name,
                        'size': size,
                        'mtime': mtime,
                        'path': item_path
                    })
            
            # Si aucun mod√®le n'est trouv√©
            if not models:
                logger.warning(f"Aucun mod√®le trouv√© dans la cat√©gorie {category}")
                return f"""‚ùå Je ne trouve aucun mod√®le dans la cat√©gorie "{display_name}".
                
Veuillez choisir une autre cat√©gorie."""
            
            # Trier les mod√®les par date de modification (plus r√©cents en premier)
            models.sort(key=lambda x: x['mtime'], reverse=True)
            
            # Construire le message de r√©ponse
            emoji = self._get_category_emoji(category)
            response = f"""{emoji} Voici les mod√®les disponibles dans la cat√©gorie {display_name} :

"""
            for model in models:
                # Formater la taille du fichier
                size = model['size']
                if size > 1024 * 1024:
                    size_str = f"{size/(1024*1024):.1f} MB"
                elif size > 1024:
                    size_str = f"{size/1024:.1f} KB"
                else:
                    size_str = f"{size} bytes"
                
                response += f"üìÑ {model['clean_name']} ({size_str})\n"
            
            response += """
Vous pouvez me dire quel mod√®le vous int√©resse en utilisant son nom ou en le d√©crivant.
Par exemple : "Je voudrais le premier mod√®le" ou "Montre-moi le mod√®le de test"."""
            
            # Mettre √† jour le contexte
            self.current_context["state"] = "choosing_model"
            self.current_context["last_action"] = "afficher_modeles"
            self.current_context["category"] = category
            self.current_context["available_models"] = models
            
            return response
            
        except Exception as e:
            logger.error(f"Erreur lors de l'affichage des mod√®les: {e}")
            logger.error(traceback.format_exc())
            return f"""‚ùå Une erreur s'est produite lors de la r√©cup√©ration des mod√®les de la cat√©gorie "{category}".
            
Veuillez r√©essayer ou contacter l'administrateur syst√®me."""

    def _clean_model_name(self, filename):
        """
        Nettoie le nom d'un mod√®le pour l'affichage.
        """
        # Enlever l'extension
        name = os.path.splitext(filename)[0]
        
        # Remplacer les underscores par des espaces
        name = name.replace('_', ' ')
        
        # Enlever les dates au format YYYY-MM-DD
        name = re.sub(r'\d{4}-\d{2}-\d{2}', '', name)
        
        # Enlever les caract√®res r√©p√©t√©s (comme 'xxxxx')
        name = re.sub(r'(.)\1{4,}', r'\1', name)
        
        # Nettoyer les espaces multiples
        name = re.sub(r'\s+', ' ', name)
        
        return name.strip() 
{
  "api_url": "http://localhost:11434/api/generate",
  "model": "llama3:latest",
  "options": {
    "temperature": 0.1,
    "num_predict": 800,
    "top_p": 0.9,
    "frequency_penalty": 0.1,
    "stop": ["\n\n", "###", "```"],
    "timeout": 10
  }
} 